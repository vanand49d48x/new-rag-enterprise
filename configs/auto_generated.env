# Auto-generated environment configuration
# Generated on: Thu Jul 31 22:23:59 EDT 2025

# Model configuration
MODEL_NAME=qwen2.5-3b-instruct-q4_k_m.gguf
LLAMA_IMAGE=ghcr.io/ggerganov/llama.cpp:server

# Performance configuration
CTX_SIZE=4096
THREADS=8
BATCH_SIZE=256
GPU_LAYERS=0

# GPU configuration (if available)
# GPU_COUNT=0
# CUDA_VISIBLE_DEVICES=
# NVIDIA_VISIBLE_DEVICES=

# System information
HOST_RAM_GB=32
HOST_CPU_COUNT=12
SYSTEM_TIER=enterprise
GPU_AVAILABLE=false

# Quality settings
N_PREDICT=128
REPEAT_PENALTY=1.1
TEMP=0.7
TOP_P=0.9
TOP_K=40
